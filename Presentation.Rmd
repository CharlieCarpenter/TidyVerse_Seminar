---
title: "Intro to Tidyverse"
author: "Charlie Carpenter & Shelby Smith"
output: 
  prettydoc::html_pretty:
    theme: cayman
    highlight: github
---

```{r, include = FALSE}
  # html_document:
  #   toc: true
  #   toc_float: true
  #   theme: spacelab
```

## Introduction

```{r, message=FALSE}
# install.packages('tidyverse')
library(tidyverse); library(magrittr)
```

### What is the 'tidyverse'?

The tidyverse is a collection of packages that are designed to work together to enhance any data cleaning, visualization, and analysis work flow. It is an enormous library of evolving packages and functions designed by Hadley Wickham and implemented in R. Packages in the tidyverse include `ggplot2` (data visualizations), `dplyr` (data manipulation), `tidyr` (data manipulation), `readr` (data imports), `purrr` (functional programming), `tibble` (advanced data frames), `magrittr` (piping operations), `stringr` (advanced string operations), `lubridate` (advanced date operations), `forcats` (advanced factor operations), `modelr` (pipelines for modeling), `broom` (tidy model output), and many others.

### Why use the 'tidyverse'?

  The tidyverse doesn't provide any new functionality to R. In fact, most of the operations you would perform using the tidyverse are available and can be performed through `base` R or the `stats` package. The primary goal of the tidyverse is to provide helpful wrappers for common operations that all work together, providing more **coherent and readable** code. For beginner coders, these tactics may even be more intuitive to understand and replicate. 

  Wickham often quotes famous computer scientist [Hal Abelson](https://en.wikipedia.org/wiki/Hal_Abelson) when discussing his philosophy for tidyverse code: 

> “Programs must be written for people to read 
> and only incidentally for machines to execute”. 
>
> `r tufte::quote_footer('--- Hal Abelson')`

  Code can easily become cumbersome to read using only `base` code. We either need to nest functions within functions
  
```{r}
unlist(tapply(mtcars[mtcars$vs == 0, ]$mpg, mtcars[mtcars$vs == 0, ]$cyl, range))
```

or we need to create multiple objects to delineate steps.

```{r}
mtcars0 <- mtcars[mtcars$vs == 0, ]
mt.ranges <- tapply(mtcars0$mpg, mtcars0$cyl, range)

do.call(rbind, mt.ranges)
```

  The tidyverse provides readable code without the need to nest functions or name multiple objects. This often yields simpler, more efficient, and relatively easy to follow code chunks:
  
```{r}
mtcars %>% 
  filter(vs == 0) %>% 
  group_by(cyl) %>% 
  summarise(range(mpg), .groups = 'drop')
```

---

## Overview

  The tidyverse is very big, so we won't be able to cover everything that this package has to offer. In this presentation we will focus on data visualization using `ggplot2`, new coding syntax using the *pipe* operator, and `dplyr`/`tidyr` for data manipulation. At the end of each section, we will have exercises for you to complete on your own as a way of practicing these implementations of the tidyverse. 

* Shelby

## Plotting with `ggplot2`

  One of the first entries in the tidyverse was the `ggplot2` package. There are many methods of creating plots within R, but `ggplot2` claims to be "one of the most elegant and most versatile" packages. I whole-heartedly agree with this claim :). 
  
 The `ggplot2` packages works on the principle of "layered graphics," in which different elements of data visualizations are layered on top of one another to tell a story greater than the sum of their individual parts. If you're interested in data visualization, Wickham's paper on the [theory of layered graphics](http://vita.had.co.nz/papers/layered-grammar.pdf) might be of interest to you!
  
  We will be walking through some examples using the `mpg` dataset from the `ggplot2` package.
  
```{r}
head(mpg) ## Dataset from the ggplot2 package
```
  
### Creating a Visualization 

  Generating a visualization from this package works by creating a base 'layer' with the `ggplot()` function and then adding specific plotting layers onto this base plot. These layers are called **geoms**, and there are several to chose from.
  
  Lets start by creating a simple scatter plot looking at cars' highway mpg, `hwy`, by the cars engine size in liters, `displ`.

```{r}
ggplot(data = mpg) + # base plot
  geom_point(mapping = aes(x = displ, y = hwy)) # specifying points
```

Here, `geom_point` was a **geom** used to specify we wanted to generate a scatter plot from this data with `displ` on the x-axis and `hwy` on the y-axis. These designations were done within the *aesthetics* of the `geom_point` function, which we will discuss in the next section. 

### Basic Aesthetics

  The true power of `ggplot2` (in my opinion) comes from the flexibility of the `aes` function. This piece controls the *aesthetics* of the **geom**. These aesthetics can be set in the base `ggplot` layer or the individual geom layers. Specifying aesthetics in the base layer will apply them to all layers of the plot.
  
  With the `aes` function we can specify **color**,
  
```{r}
ggplot(data = mpg) +
  geom_point(mapping = aes(x = displ, y = hwy, color = drv)) 
```

**shape**,

```{r}
ggplot(data = mpg) +
  geom_point(mapping = aes(x = displ, y = hwy, shape = drv)) 
```

and **size** of plotting aspects.

```{r, warning = FALSE}
ggplot(data = mpg) +
  geom_point(mapping = aes(x = displ, y = hwy, size = drv)) 
```

We can also add in multiple aesthetics for clearer groupings.

```{r}
ggplot(data = mpg) +
  geom_point(mapping = aes(x = displ, y = hwy, 
                           shape = drv, color = drv)) 
```

### Smoothers

  A great addition from `ggplot2` is it's built in smoother functions. The default for smaller data sets is to use a *loess* smoother. Other available options include "gam", "lm", and "glm", among others. 
  
```{r, message = FALSE}
ggplot(data = mpg) +
  geom_smooth(mapping = aes(x = displ, y = hwy, color = drv)) 
```

Above, we can see the specification of `geom_smooth` as opposed to `geom_point` alters the plotting layer from the previously seen scatter plot to a smoothing line instead. 


Here, we have adjusted the smoothing method to 'lm' instead of a 'loess' smoother and can see the linear relationships of each category within the `drv` variable. 

```{r, message = FALSE}
ggplot(data = mpg) +
  geom_smooth(mapping = aes(x = displ, y = hwy, color = drv),
              method = 'lm', se = FALSE) # Linear model, no error bars
```

### Layering

  As mentioned earlier,  `ggplot2` is built using a theory of "layered graphics." In practice, this means we can "layer" multiple geoms! This can be done by stringing together multiple geoms using a `+` between each layer.
  
```{r, message = FALSE}
ggplot(data = mpg) +
  # A layer for the scatter plot 
  geom_point(mapping = aes(x = displ, y = hwy,
                            shape = drv, color = drv)) +
  # A layer for adding a smoother on top of the scatter plot
  geom_smooth(mapping = aes(x = displ, y = hwy, color = drv),
              show.legend = FALSE) ## Suppress this legend because the scatter plot already generates one!
```
  
  There is a lot of flexibility in the customization options available through the `ggplot2` package. The code below shows an example of using aesthetics within the base plot which will be applied to every layer in addition to using geom-specific aesthetics which will only be applied to that layer of the visualization.
  
```{r, message = FALSE}
ggplot(data = mpg, aes(x = displ, y = hwy, color = drv)) + # 'Global' Aesthetics
  geom_point(aes(shape = drv)) + # 'Geom specific' aesthetic
  geom_smooth(aes(linetype = drv),
              show.legend = FALSE) + # Suppress this legend 
  facet_wrap(~ drv) + # Create subplots by a variable
  labs(title = "main Title", subtitle = 'subtitle', caption = 'Insert Caption Here',
       y = "MPG on Highway", x = "Engine Size (L)") + # Custom Labels using labs() 
  theme_bw() # New plot theme
```

### Other Plot Types

  Obviously, we can make more than just scatterplots. Below are two examples of other plots styles available in `ggplot2`
  
**Boxplots**

```{r}
ggplot(mpg, aes(x=class, y=hwy, fill = class)) + # 'Global' aes
  geom_boxplot() + # make a boxplot 
  theme_minimal() # Adjusting the x-axis group labels to be angled
```

**Bar Charts**

```{r}
ggplot(mpg, aes(x=class, y=hwy, fill = drv)) + # 'Global' aesthetics
  geom_col() + # make a boxplot
  theme_classic()
```
 
 **1-Dimensional Plots**
 
 It is also possible to generate very simple "1-Dimensional" plots with this package. We don't necessarily have to be comparing two variables to implement the `ggplot2` package. Let's see if we can visualize the *counts* of the different `class` sizes of vehicles in our dataset, for example: 
  
```{r}
ggplot(data = mpg, aes(x = class, fill = class)) + # Only assigning an x-variable global aesthetic
  geom_bar() # bar chart

#Note: fill assigns a color to each condition, but doesn't otherwise alter the figure
```

  By only specifying the x-axis in the global aesthetics, and layering this with a bar chart, we get a frequency bar chart of the discrete variable `class` that is observed in our data set. 

### `ggplot2` Exercises

The supplemental exercises throughout the documentation will be developed using the *gapminder* data set as part of the `dslabs` package. The `dslabs` package is full of data sets and functionalities often used in the realm of data science and statistics for data analysis practice. The *gapminder* dataset contains health and income data from 184 countries between the years 1960 and 2016. Variables include `country`, `year`, `infant_mortality`,  `life_expectancy`, and many others. 

```{r}
#install.packages('dslabs')
library(dslabs)
head(gapminder)
```
1. To view the distribution of discrete variables like `continent`, try generating a bar chart that counts the number of observations of each `continent` in the dataset. Once you have this generated, try setting `fill = continent` within the global aesthetics & see how your visualization changes. 

2. What is the distribution of `life_expectancy` over the whole data set? (Hint: use the `geom_density` layer, after mapping the x-variable to  `life_expectancy`)

3. Can we group the previous exercise by continent? Try setting "fill = `continent`" after "x = `life_expectancy`". (Hint: `geom_density(alpha = 0.5)` makes the density distributions transparent). 

4. How has `life_expectancy` changed over the years, `year`, by `continent`? Try fitting this first with a scatter plot, and then with a 'lm' smoother to see two different ways of visualizing this. (Hint: one is much simpler on the eye!)



### Extentions of `ggplot2`

  Since R is an open source software with a very active community, many programmers have created plotting packages with custom geoms for plotting different data in the style of `ggplot2`. A few examples include `ggtree` for (phylogenetic) trees, `ggdendro` for generic dendrograms, `ggrepel` for labeling, and `ggnetwork` for network/graph data.

* Charlie

---

## The 'pipe' function
  
  The *pipe* function, ``%>%``, is a key facet of the tidyverse from the `magrittr` package.

\newline 

> “No matter how complex and polished the individual operations are,
> it is often the quality of the glue that most directly determines
> the power of the system.
> 
> `r tufte::quote_footer('--- Hal Abelson')`

  The pipe works similarly to other in-line functions such as ``%in%``, ``%*%``, or ``%%``, except instead of performing a function on two objects, it takes the object on the left and moves it to the first argument of the function on the right.
  
```{r}
## Pipe into function
head(mtcars) 
mtcars %>% head 

## Pipe into function and include arguments
plot(mtcars$mpg, main = "MPG")
mtcars$mpg %>% plot(main = "MPG") 
```
  
  The format for adding *geoms* to a `ggplot` was an early formulation of this idea of stringing multiple functions together through an external function.
  
  The following are pairs of operations that are all equivalent to one another. By looking at the same thing done three different ways, it is clear that operations with fewer steps don't benefit from piping objects, but multi-step processes quickly become easier to read & sift through with the implementation of a pipe.
  
```{r, eval = FALSE}
## Nested functions
arrange(
  summarise(
    group_by(
      filter(mtcars, mpg > 15),
      cyl
    ), 
    mean(wt), .groups = 'drop'
  ),
  desc(cyl)
)

## Multiple Names
filts <- filter(mtcars, mpg > 15)
grpby <- group_by(filts, cyl)
sumry <- summarise(grpby, .groups = 'keep')
arang <- arrange(sumry, desc(cyl))
```

```{r}
## Piping for clean code
mtcars %>% 
  filter(mpg > 15) %>% 
  group_by(cyl) %>% 
  summarise(mean(wt), .groups = 'drop') %>% 
  arrange(desc(cyl))
```

  The last option is easier to read and more concise than either of the previous ones. Forgoing the use of nested functions means you don't have to think and type *backwards*; you can think, type, and read in the same direction using pipes. (No more useless intermediate objects *data1, data2, data3,...*.) We only have to name important steps or meaningfully different objects. In no small way, this solves one of Phil Karlton's two hard problems in computer science:

\newline

> "There are only two hard things in computer science:
> cache invalidation and naming things."
>
> `r tufte::quote_footer('--- Phil Karlton')` 

  The *pipe* is also able to place the left hand object anywhere in the right hand function you specify with a `.`, eliminating the need to redundantly specify your data frame. There really isn't any place you can't use the pipe function! Le pipe is le best!
  
```{r, eval = FALSE}
mtcars %>% lm(mpg~cyl, data = .) 
```

  There are multiple piping functions available in the `magrittr` package: `%<>%`, `%T>%`, `%$%`. We won't cover these, but they each have interesting functionality that can be very helpful.

## Data Manipulation

  As we said earlier, there aren't many things you can do with the tidyverse that you can't do with `base` R. In fact, the tidyverse is mostly built out of `base` R (and a little `Rcpp`), like R is built out of C code.
  
### Extracting Variables  
  
##### Base Extraction

  We're all familiar with extraction methods in `base`. 

```{r}
## First column as vector
mtcars[,1] 
## or
mtcars[,'mpg']
## or
mtcars$mpg
## or (unnecessarily)
getElement(mtcars, 'mpg')
```

  We can also maintain the original dimension of the object using `drop = FALSE` or selecting multiple columns.

```{r}
head( mtcars[,1, drop = FALSE] )

head( mtcars[,1:2] ) ## or mtcars[, c('mpg', 'cyl')]
```

##### Tidyverse Extraction

  Tidyverse provides the `pull` and `select` functions to replace the extractors from `base`. `pull` is used to extract a *single* column and simplify it to a vector, and `select` is used to extract *one or more* columns and maintain the data's original structure (i.e. data.frames remain data.frames). 

```{r}
## First column as vector
pull(mtcars, 1) # same as mtcars[,1]

## or with the 'pipe'
mtcars %>% pull(1)
mtcars %>% pull(mpg) # same as mtcars$mpg
```
  
  Alternatively, we can maintain the data.frame structure using the `select` function from the *dplyr* package. This is equivalent to using the `drop = FALSE` argument of the `[]` function.
  
```{r, eval = F}
select(mtcars, 1)

## or selecting multiple cols
select(mtcars, 1,2,3)

## equivalently
mtcars %>% select(1:3)

## Selecting columns specified by name (most common use)
mtcars %>% select(mpg, hp, wt, qsec)
```

  The `select` function also gives the user flexible and intuitive functions for selecting ranges, complements, intersections and unions, or specifying selection through regular expressions with helper functions.
  
```{r, eval = FALSE}
## Selecting vars 'mpg', 'cyl', 'disp', and 'hp'
mtcars %>% select(mpg:hp)

## Selecting using regular expression helper functions
mtcars %>% 
  select(starts_with('d')) ## all variables that start with 'd'

mtcars %>% 
  select(contains('a')) ## all variables with an 'a' in their name

## Select unions of elements (or intersections with `&`)
mtcars %>% 
  select(starts_with('c') | ends_with('arb'))

## Or rename variables through the `select` function
mtcars %>% 
  select(Miles_Per_Gal = mpg) ## new_name = original_name
```

* Shelby

### Subset and Filter

##### Base

```{r}
subset(mtcars, disp >= mean(disp))
```

  Note that this is one of the few times that base code uses 'non-standard evaluation.' This means that it captures input as '*expressions*' to be evaluated within the function's environment, i.e. we don't need to use any *extraction* functions such as `[]` or `$` within the argument. The `subset` function would look like this: `subset(mtcars, mtcars$disp >= mean(mtcars$disp))` if it worked like most `base` functions.

##### Tidyverse

  The tidyverse primarily operates by capturing arguments as *expressions*. They call this method of controlling the environment in which functions are executed *tidy evaluation*. This greatly simplifies most of the syntax required and is a major contribution to keeping code 'tidy.' 

```{r}
## Multiple filtering options 

## Equivalent of multiple '&' statements in subset
mtcars %>% 
  filter(disp >= mean(disp),
         carb == 4,
         vs == 0)
```

### Subset and Extraction

##### Base

```{r}
## Subset data.frame
subset(mtcars, carb == 4, select = c(mpg, cyl, carb))

## Subset to vector
subset(mtcars, carb == 4, select = cyl, drop = TRUE)
```

##### Tidyverse

```{r}
## Subset data.frame
mtcars %>% 
  filter(carb == 4) %>% 
  select(mpg, cyl, carb)

## Subset to vector
mtcars %>% 
  filter(carb == 4) %>% 
  pull(cyl)
```

### Adding columns to a Dataframe

  Adding columns and performing operations on existing columns is an essential part of data cleaning. Whether it is manipulating a variable or adding new columns that are functions of existing ones, it is important that the operations you perform are clear and reproducible. When someone inherits your code (or when you have to revisit it months later) there should be very little guessing as to what the code is doing. Commenting throughout is always the best practice, but we all know that our good commenting habits come and go.
  
##### Base

  Adding columns to a dataset is simple and easy to read when the operation is small.
  
```{r}
mtcars$log.mpg <- log(mtcars$mpg)
```

  Here it easy to see how the need to name the data and select the variable with `$` over and over can make relatively simple operations hard to read/ and yields overly busy code chunks. One might even say, they weren't as tidy as they could be. 

```{r}
mtcars$s.mpg <- (mtcars$mpg - mean(mtcars$mpg))/sd(mtcars$mpg)

# Or just use the 'scale' function
# mtcars$s.mpg <- scale(mtcars$mpg)
```
  
##### Tidyverse  
  
   We can use the `mutate` function to add a new column to our data.frame and take advantage of the *tidy evaluation* from the tidyverse. This prevents us from needing to name the data set every time.
  
```{r, eval = F}
mtcars %>% ## Adding a new column called s.mpg
  mutate(s.mpg = (mpg - mean(mpg)/sd(mpg)) ) 
```

  We can also add in multiple columns in one mutate step. Note that we can create a variable (like *log.mpg*) and then make additional variables based on this new variable. This is because most of the tidyverse works with something called 'lazy evaluation.'

```{r, eval = FALSE}
mtcars %>% 
  mutate(s.mpg = (mpg - mean(mpg)/sd(mpg)),
         log.mpg = log(mpg),
         ls.mpg = (log.mpg - mean(log.mpg)/sd(log.mpg)) # Note we are using the previously created log.mpg variable to calculate a new variable
         )
```
  
  Alternatively, we can get super fancy and apply functions across multiple columns at once. However, I think we start to lose some of the "readability" that is such a bonus from the tidyverse when we do this. 
  
```{r}
mtcars %>% 
  mutate(across(where(is.numeric), scale)) %>% 
  head

## or maybe
mtcars %>% 
  mutate(across(starts_with("c"), log)) %>% 
  head
```
  
* Charlie

### Grouped Functions

  Applying functions to a variable grouped by another variable (stratifying) is an important concept in many stats methods. In `base` the simplest way to accomplish this kind of process is to use the `tapply` function. It even has a useful *snippet* when you just type 'tapply' and hit enter.

##### Base

```{r}
## Getting the mean mpg by cyl group
tapply(mtcars$mpg, mtcars$cyl, mean)

## Making a custom function
tapply(mtcars$mpg, mtcars$cyl, function(x) round(mean(x), 2))
```

  As useful as this is, we can only group by one variable! What if we want to group by multiple variables? In `base` you can use the `split` function with `interaction`, but the ability for multiple grouping variables is already coded up into the tidyverse.
  
##### Tidyverse

  We can use the `group_by` function to create lasting groups within our data.frame. We can use the extremely useful `summarise` function to get really nicely calculated summary statistics.

```{r}
## summarise our data set by one group
mtcars %>% 
  group_by(cyl) %>% 
  summarise(Mean_mpg = mean(mpg), SD_mpg = sd(mpg),
            Mean_disp = mean(disp), SD_disp = sd(disp),
            .groups = 'drop')

## group by multiple variables
mtcars %>% 
  group_by(cyl, vs) %>% 
  summarise(n = n(), Mean_mpg = mean(mpg), SD_mpg = sd(mpg),
            Mean_disp = mean(disp), SD_disp = sd(disp),
            .groups = 'drop')
```

  The `group_by` can also be very useful when combined with `mutate`. 
  
```{r}
## Scaling mpg within cyl category
mtcars %>% 
  group_by(cyl) %>% 
  mutate(s.mpg = scale(mpg))
```

### Split, Apply, Combine

  The `mutate` and `summarise` functions are very convenient for doing many simple operations that return either a single vector or value, respectively. However, when we want to do larger operations and return more complex objects, the tidyverse offers a family of very useful functions.
  
  The *split-apply-combine* family from the `plyr` package all take a data frame, an array, a list, or a matrix and return an array, a data frame, a list, or discard results (useful for plotting or saving output). For a complete description of these methods and the philosophy behind them, Wickham's [Split-Apply-Combine paper](https://vita.had.co.nz/papers/plyr.pdf) is a very easy read.
  
**Input: data.frame; Output: data.frame**

```{r}
mtcars %>% 
  plyr::ddply(~ cyl, .fun = function(set){
    ## linear model for each cly level
    mod <- lm(mpg ~ disp, data = set) 
    
    ## Model coefficients
    coef(mod)
  })
```

**Input: list; Output: data.frame**

```{r}
## Making a list to work with
l.mtcars <- split(mtcars, mtcars$cyl)

l.mtcars %>% 
  plyr::ldply(.fun = function(set) {
    ## linear model for each cly level
    mod <- lm(mpg ~ disp, data = set) 
    
    ## Model coefficients
    coef(mod)
  })
```

**Input: data.frame; Output: discarded**

```{r}
par(mfrow=c(1,3))
mpg %>% 
  plyr::d_ply(~ drv, .fun = function(set){
    
    ## Linear model for regression line
    .mod <- lm(hwy ~ displ, data = set)
    .coef <- coef(.mod)
  
    ## Title
    title <- paste('drv =', unique(set$drv))
    
    ## Overcomplicated code for colors
    if(unique(set$drv) == 4){
      line.col <- 'firebrick3'
    } else if(unique(set$drv) == 'f'){
      line.col <- 'deepskyblue2'
    } else line.col <- 'forestgreen'
    
    plot(hwy ~ displ, data = set, col = line.col, main = title)
    abline(a = .coef[1], b = .coef[2], col = line.col)
  })

```

### Data Manipulation Exercises

```{r}
head(gapminder)

```

1. Extract data from the *gapminder* dataset that contains the following information:
- Country: Belize
- Year: 1990
- Life_expectancy
- Population
- Continent

2. Maybe we're interested in calculating the gross domestic product per capita. Use the mutate function & write an expression to calculate this, and create a new column in the dataframe. (Hint: gdp / population)

3. Build on your code from question 2, and find out the top 3 GDP per capita in each continent
(Hint: use %>% head(3) at the end to only select the top 3). 

### Challenge Exercises using the NYC Flights Data

  The R package `nycflights13` contains data about all flights that departed one of the three New York City airports (JFK, LGA, and EWR) in 2013. You can probably guess, this is no small dataset. This first code chunk simply performs an inner join on two datasets in order to match the data on the `carrier` column. The original flights dataset only  has the two letter 'key' for each flight carrier; merging these together allows us to see the Airline names as well. 
  
```{r}
#install.packages('nycflights13')
library(nycflights13)
data(flights)

data(airlines)

flights_carrier <- flights %>%
  inner_join(airlines, by=c('carrier'='carrier'))

glimpse(flights_carrier)
```

1. Using the `flights_carrier` dataset, create a new data set, `flights2` that contains the carrier name, year, month, day, departure delay, arrival delay, origin airport, destination airport, and flight number.

2. How many unique flight routes does American Airlines Inc. run departing from the New York area? (Hint: use the n_distinct() command within `summarise`)

3. How many unique flight routes does American Airlines Inc. run from each of the three area airports?

4. What is the average departure delay of a American Airlines Inc. flight leaving JFK? LGA? EWR? What about leaving any New York area airport?

* Shelby

---

## Summary

  Again, there is nothing tidyverse does that you can't do using base R functions (with the exception being some of the visualizations from `ggplot` and its extensions). Despite this, people seem to love the tidyverse. Here is a post from [Quora](https://www.quora.com/Where-do-you-stand-on-Base-R-vs-the-tidyverse) where most people have nothing but great things to say. 
  However, there are plenty of people who are against this new coding style, like in this blog post that sparked some controversy: [Why I don't use the tidyverse](https://blog.ephorie.de/why-i-dont-use-the-tidyverse). Some make the claim that it is harder (or at least no easier) to teach the tidyverse than base R: [Why it is hard to teach the tidyverse](https://github.com/matloff/TidyverseSkeptic). Here I tend to agree. The tidyverse is only 'easier' to understand if you already understand R.

  At the worst, the tidyverse seems like a reworking of `base` R functions so that they don't have the small things from `base` that annoyed Hadley (e.g. `tibble`). At best, it is large improvements over `base` functions with the implementation of things like `ggplot` and `%>%`.

### Advantages

1. Excellent plotting functions (ggplot is beautiful)
2. Easier for humans to read and arguably simpler to write
    + the *pipe* function allow us to code how we talk and think

### Disadvantages

1. Still a 'work in progress'. Many functions are continuously changing
    + new `.groups` argument in the `select` function
    + melt/cast -> gather/spread -> pivot_longer/pivot_wider
2. "Rectangular" data structure isn't adopted by everyone. 
    + Bioconductor requires S4 objects

---
## Want to keep learning about the tidyverse?

* Textbook: [R for Data Science](https://r4ds.had.co.nz/)

* An equivalent for [base R](https://cran.r-project.org/doc/contrib/de_Jonge+van_der_Loo-Introduction_to_data_cleaning_with_R.pdf)

* Textbook on coding style: [R Style Guide](https://style.tidyverse.org/)

* Data manipulation with dplyr: [`dplyr` cheatsheet](https://rstudio.com/wp-content/uploads/2015/02/data-wrangling-cheatsheet.pdf)

* How to program with tidyverse:
[Programming with dplyr](https://dplyr.tidyverse.org/articles/programming.html)
  + I don't recommend programming with the tidyverse. Since it is 'always improving' it is always changing. Your programming could become invalid with a new tidyverse update, e.g. `spread` and `gather` are no longer 'supported' from the tidyverse.
  
* A talk from David Robinson, Chief Data Scientist at DataCamp, at the 2018 RStudio Conference about early teaching strategies in Data Science: [Teaching the Tidyverse to beginners](https://rstudio.com/resources/rstudioconf-2018/teach-the-tidyverse-to-beginners/)

* Interested in learning more about `ggplot2`? Here are the [Top 50 ggplot2 Visualizations - The Master List (With Full R Code)](http://r-statistics.co/Top50-Ggplot2-Visualizations-MasterList-R-Code.html) and the [`ggplot2` cheatsheet](https://rstudio.com/wp-content/uploads/2015/03/ggplot2-cheatsheet.pdf).

